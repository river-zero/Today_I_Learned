- [멀티스레드](#멀티스레드)
- [Atomic](#atomic)
- [Lock](#lock)
- [DeadLock](#deadlock)
- [Lock 구현 방법](#lock-구현-방법)
- [SpinLock](#spinlock)
- [Sleep](#sleep)
- [Event](#event)
- [Condition Variable](#condition-variable)
- [Future](#future)
- [메모리 모델](#메모리-모델)

# 멀티스레드
예를 들어 한식, 일식, 패밀리 레스토랑과 같이 여러 식당이 존재한다고 하자. 각 식당의 직원들에 영혼이 빙의해서 일을 한다. 이 작업을 엄청 빨리 하면 마치 직원들이 동시에 움직이는 것처럼 보이는 것이다. 식당은 프로세스, 직원은 스레드, 영혼은 CPU 코어에 해당한다. 하나의 CPU 코어가 하나의 스레드를 전담마크하는 상황이 가장 이상적이다.

멀티스레드 환경은 힙 영역과 데이터 영역을 모든 스레드가 공유 가능하므로 데이터를 두 번 관리할 필요없이 같은 데이터를 여러 명이 동시에 참조가 가능한 장점이 있다. 대신, 동시에 데이터에 접근하고자 하면 여러 문제가 발생할 수 있다.

```
#include "pch.h"
#include "CorePch.h"

#include <iostream>
#include <thread>
// 어떤 운영체제든 범용적인 코딩 가능

void HelloThread_1() {
	cout << "Hello, Thread!" << endl;
}

void HelloThread_2(int32 num) {
	cout << num << endl;
}

int main() {
	vector<std::thread> v;

	std::thread t1(HelloThread_1);
	std::thread t2(HelloThread_2, 10);
	// main 스레도와 동시에 병렬적 실행

	for (int32 i = 0; i < 10; i++) {
		v.push_back(std::thread(HelloThread_2, i));
	}

	int32 count = t1.hardware_concurrency();
	// CPU 코어 개수 얼마인지 힌트를 줌
	// 정보 추출이 힘들다면 0을 리턴

	auto id = t1.get_id();
	// 스레드마다 부여되는 고유한 아이디 획득
	// 아직 스레드가 배정되기 전이라면 0으로 부여

	t1.detach();
	// 스레드 객체 t와 실제 구동 스레드와 연결 끊음
	// 왠만해선 잘 쓰지 않음

	// t 객체가 실행 중 또는 실행 가능한지 확인
	// 그러니까 객체와 실제 스레드가 연결되었는지 확인
	if (t1.joinable()) {
		t1.join();
		// t 스레드가 끝나기를 기다림
	}
	if (t2.joinable()) {
		t2.join();
	}
	for (int32 i = 0; i < 10; i++) {
		if (v[i].joinable()) {
			v[i].join();
		}
	}

	cout << "Hello, Main!" << endl;
}
```

# Atomic
멀티 스레드 환경에서는 공유 데이터 관련 문제가 언제나 골칫거리다. 특히 힙이나 데이터 영역 같은 경우에는 더욱 그렇다. 따라서 오류를 예방하기 위해서는 순서가 보장이 되어야 한다. 이를 동기화 기법이라 한다. 그 중 하나가 Atomic 기법이다. 완전히 실행되거나 아니면 아예 실행되지 않는 두 가지 상태만을 가지는 것을 나타낸다. Atomic 연산은 데이터를 읽고 쓰는 동안 다른 스레드가 접근하지 못하도록 막아 안정성을 보장한다.

```
#include "pch.h"
#include "CorePch.h"

#include <iostream>
#include <thread>
#include <atomic>

atomic<int32> sum = 0;

void Add() {
	for (int32 i = 0; i < 100'000; i++) {
		sum.fetch_add(1);
	}
}

void Sub() {
	for (int32 i = 0; i < 100'000; i++) {
		sum.fetch_add(-1);
		// 멀티 스레드 환경에서 공유된 변수에 안전하게 값을 증가시키는데 사용
		// 연산이 느리므로 꼭 필요할 때만 사용
	}
}

int main() {
	std::thread t1(Add);
	std::thread t2(Sub);

	t1.join();
	t2.join();

	cout << sum << endl;
}
```

# Lock
아토믹 연산도 한계가 있다. 그래서 등장한 것이 Lock이다. 순서를 정해서 한 명만 접근하도록 유도하는 것이다. 일종의 자물쇠라고 생각하면 된다. 아무래도 느리게 동작할 수 밖에 없다. 락은 거는 범위에 따라서 동작이 크게 달라지는 것을 염두해 두어야 한다.

락을 잊고 해제하지 않는 것은 무한 대기나 데드락을 초래할 수 있다. 이를 방지하기 위해 RAII 패턴(클래스를 만들어 생성자에서 잠그고 소멸자에서 해제하는 자동 시스템 구축)을 사용하거나, C++에서는 std::lock_guard 및 std::unique_lock(잠금 시점 미루기 가능)과 같은 스마트 락을 활용할 수 있다.

이때, std::adopt_lock과 함께 사용하면 이미 잠긴 뮤텍스를 안전하게 lock_guard에 넘길 수 있으며, 뮤텍스의 안전한 소유권 전달을 보장할 수 있다.

```
#include "pch.h"
#include "CorePch.h"

#include <iostream>
#include <thread>
#include <atomic>
#include <mutex>

vector<int32> v;
mutex m;

void Push() {
	for (int32 i = 0; i < 10000; i++) {
		m.lock();   // 잠금
		v.push_back(i);
		m.unlock(); // 해제
	}
}

int main() {
	std::thread t1(Push);
	std::thread t2(Push);

	t1.join();
	t2.join();

	cout << v.size() << endl;
}
```

# DeadLock
데드락은 일종의 눈치게임 실패 상황과 같다. 두 개 이상의 스레드나 프로세스가 서로가 가진 자원을 기다리며 무한히 진행하지 못하는 상태를 나타낸다. 시스템은 빠져나갈 방법이 없고, 작업이 멈추게 되며 시스템의 안정성과 성능에 영향을 미친다.

# Lock 구현 방법
자물쇠를 이미 잠근 상황에서 할 수 있는 방법에는 대표적으로 SpinLock, Sleep, Event 이렇게 세 가지가 있다. 하나만 사용하는 것이 아니라 적절히 섞어 쓸 수도 있다.

# SpinLock
Lock을 구현하는 방법 중 하나다. 그냥 무작정 기다린다. 임계 영역에 진입하기 전에 스핀락을 획득하고 임계 영역을 빠르게 실행한 다음 스핀락을 해제한다. 스핀락은 락을 짧은 시간 동안 소유하고자 할 때 유용하며, 대기 시간이 길 경우 성능 저하를 가져올 수 있다.

컨텍스트 스위칭 비용이 없고, 락 프리이며, 오버헤드가 적다는 장점이 있다. 반대로 CPU 사용량이 증가하고, 특정 스레드가 락을 오랫동안 보유할 경우 다른 스레드들이 스핀락을 기다리면서 CPU 자원이 낭비되는 단점도 있다.

스핀락은 경쟁 조건을 방지하기 위해 주로 CAS(Compare And Swap)과 같은 원자적인 연산을 사용해 구현한다. CAS의 기본 아이디어는 이렇다. 메모리 위치의 현재 값을 읽고 원하는 새 값과 비교한다. 만약 두 값이 같다면 해당 메모리 위치의 값을 새 값을 교체하고, 그렇지 않다면 아무것도 하지 않는다. 이는 다른 스레드가 이미 값을 변경했음을 뜻한다. CAS는 스레드 간의 경합 상태를 효과적으로 제어하고 원자적인 연산을 제공하여 스레드 안전성을 유지한다.

```
#include "pch.h"
#include "CorePch.h"

#include <iostream>
#include <thread>
#include <atomic>
#include <mutex>

class SpinLock {
public:
	// 시그니처를 맞추기 위해 소문자
	void lock() {
		bool expected = false;
		bool desired = true;

		// 될 때까지 무한 루프
		while (_locked.compare_exchange_strong(expected, desired) == false) {
			expected = false;
			// 새로운 시도를 위해 expected 값을 초기 상태로 되돌려놓기 위함
			// 성공하면 루프 탈출
		}
	}

	void unlock() {
		_locked.store(false);
		// store 연산은 이러한 원자적인 연산 중 하나
		// 변수에 값을 저장할 때 다른 스레드가 중간에 값을 읽지 못하도록 보장
	}

private:
	// volatile bool _locked = false;
	// C++에서 volatile은 컴파일러에게 최적화를 하지 말라고 명시적으로 부탁하는 역할
	// 변수나 객체가 예상치 못한 순간에 변경될 수 있는 상황을 예방
	
	atomic<bool> _locked = false;
};

int32 sum = 0;
mutex m;
SpinLock spinLock;

void Add() {
	for (int32 i = 0; i < 100000; i++) {
		lock_guard<SpinLock> guard(spinLock);
		sum++;
	}
}

void Sub() {
	for (int32 i = 0; i < 100000; i++) {
		lock_guard<SpinLock> guard(spinLock);
		sum--;
	}
}

int main() {
	thread t1(Add);
	thread t2(Sub);

	t1.join();
	t2.join();

	cout << sum << endl;
}
```

# Sleep
Lock을 구현하는 방법 중 하나다. 운영체제는 스케줄링을 위해서 타임 슬라이스라는 일종의 시간 쿠폰을 발행한다. 스레드가 자신의 쿠폰을 모두 사용하면 슬립 상태로 전환되고 다른 스레드에게 CPU 자원을 양보한다. 슬립 상태로 전환된 스레드는 나중에 다시 스케줄링 대기열에 들어가고 다음 기회를 기다린다. 즉, 스레드가 락을 얻지 못하는 경우 슬립하고 다른 스레드에게 CPU를 양보함으로써 데드락을 방지합니다.

슬립은 스레드가 CPU 리소스를 계속해서 사용하지 않도록 하고 다른 스레드에게 기회를 주므로 CPU 자원을 효과적으로 활용할 수 있다는 장점이 있다. 반대로, 컨텍스트 스위칭으로 인한 비용도 있다는 단점이 있다.

```
#include "pch.h"
#include "CorePch.h"

#include <iostream>
#include <thread>
#include <atomic>
#include <mutex>

class Sleep {
public:
	void lock() {
		bool expected = false;
		bool desired = true;

		while (_locked.compare_exchange_strong(expected, desired) == false) {
			expected = false;

			// this_thread::sleep_for(std::chrono::milliseconds(100));
			this_thread::sleep_for(100ms);
			// this_thread::yield();
		}
	}

	void unlock() {
		_locked.store(false);
	}

private:
	atomic<bool> _locked = false;
};

int32 sum = 0;
mutex m;
Sleep spinLock;

void Add() {
	for (int32 i = 0; i < 100000; i++) {
		lock_guard<Sleep> guard(spinLock);
		sum++;
	}
}

void Sub() {
	for (int32 i = 0; i < 100000; i++) {
		lock_guard<Sleep> guard(spinLock);
		sum--;
	}
}

int main() {
	thread t1(Add);
	thread t2(Sub);

	t1.join();
	t2.join();

	cout << sum << endl;
}
```

# Event
Lock을 구현하는 방법 중 하나다. 식당 관리자가 손님에게 차례가 오면 쪽지를 보내고, 손님들은 쪽지를 기다리며 대기한다. 쪽지를 받으면 손님들은 깨어나서 작업을 시작하는 방식이다. 여기서 쪽지가 이벤트에 해당한다. 어느 정도의 대기가 필요한 상황에서 유용하다.

이벤트를 사용하면 대기하는 동안 CPU 자원을 낭비하지 않고, 비동기 프로그래밍에서 유용하게 활용되며, 대기 시간을 최소화하는 장점이 있다. 반대로, 너무 많은 스레드가 이벤트를 기다리는 경우에는 성능 저하가 발생할 수 있다.

```
#include "pch.h"
#include "CorePch.h"
#include <iostream>
#include <thread>
#include <atomic>
#include <mutex>
#include <windows.h>

mutex m;
queue<int32> q;
HANDLE handle;

void Producer() {
	while (true) {
		{
			unique_lock<mutex> lock(m);
			q.push(100);
		}

		::SetEvent(handle);
		// 이벤트가 시그널 상태로 변경
		// 이벤트를 기다리는 스레드가 이를 감지하고 실행을 재개

		this_thread::sleep_for(100ms);
	}
}

void Consumer() {
	while (true) {
		::WaitForSingleObject(handle, INFINITE);
		// 시그널 상태가 될 때까지 여기서 대기
		// 자동이므로 논시그널 상태로 바꿔줌
		// 수동이라면 ::ResetEvent(handle);

		unique_lock<mutex> lock(m);
		if (q.empty() == false) {
			int32 data = q.front();
			q.pop();
			cout << data << endl;
		}
	}
}

int main() {
	handle = ::CreateEvent(NULL, FALSE, FALSE, NULL);
	// 커널에서 관리되는 객체
	// 입력값은 보안 속성, 수동 또는 자동 리셋, 초기 상태, 이름
	// 일종의 번호표를 리턴

	thread t1(Producer);
	thread t2(Consumer);

	t1.join();
	t2.join();

	::CloseHandle(handle);
}
```

# Condition Variable
이벤트와 매우 유사하나 커널 오브젝트가 아닌 유저 레벨 오브젝트라는 차이점이 있다. 커널 레벨에서는 다른 프로그램에서도 상호작용이 가능하지만 유저 레벨에서는 같은 프로그램 내에서만 사용이 가능하다. 조건을 보고 코드를 진행할지 말지 결정하기 때문에 조금 더 효율적이다. 공용으로 사용하는 큐를 두고 한 쪽은 데이터를 밀어넣고 한 쪽은 사용하는 경우에 유용하다.

notify_one()을 할 때 진짜 Lock을 건 것이 아니다. 이걸 가짜 기상이라고 하는데, 그래서 추가적으로 조건을 크로스체킹하는 것이다. 어지간해서는 이 방법이 유리하다. 물론 락을 거는 시점과 통지하는 시점이 분리가 되다 보니 그 사이에 틈이 생기는 것도 있다.

```
#include "pch.h"
#include "CorePch.h"
#include <iostream>
#include <thread>
#include <atomic>
#include <mutex>
#include <windows.h>

mutex m;
queue<int32> q;

condition_variable cv;

void Producer() {
	while (true) {
		{
			// 1. Lock을 걸고
			unique_lock<mutex> lock(m);

			// 2. 공유 변수 값 수정
			q.push(100);
		} // 3. Lock을 풀고

		// 4. 조건변수 통해 다른 스레드에게 통지
		cv.notify_one(); 
	}
}

void Consumer() {
	while (true) {
		unique_lock<mutex> lock(m);
		cv.wait(lock, []() {return q.empty() == false; });
		// 1. Lock을 잡으려고 시도
		// 2. 조건을 확인
		// - 만족O -> 빠져나와 이어서 코드 진행
		// - 만족X -> Lock을 해제하고 대기 상태로 전환
		
		{
			int32 data = q.front();
			q.pop();
			cout << data << endl;
		}
	}
}

int main() {
	thread t1(Producer);
	thread t2(Consumer);

	t1.join();
	t2.join();
}
```

# Future
단발성 이벤트의 경우에는 다른 방식이 필요할 수 있다. 10분짜리 일에 직원을 한 명을 더 고용하는 건 낭비이기 때문이다. 그럴때 Future 방식을 사용한다. 결과를 기다리지 않고 다른 작업을 수행할 수 있으므로 비동기 코드를 효율적으로 작성하는 데 도움이 된다.

deferred 옵션이라면 지연해서 실행하고, async 옵션이라면 별도의 스레드를 만들어서 실행하고, deferred | async 옵션이라면 둘 중 하나를 골라 실행한다.

std::promise는 std::future 객체와 관련된 값을 설정하는 데 사용한다. std::future와 함께 사용되어 작업 결과를 반환하거나 예외를 던질 수 있다. 따라서 여러 스레드끼리 통신을 하고 결과물을 받아줘야 할 때 유용하다. std::future는 스레드를 만들어서 결과를 받는다면 std::promise는 이미 존재하는 스레드에 일감이라는 개념을 만들어 넘기고 결과물을 future로 받는 방식이라고 볼 수 있다.

std::packaged_task는 역시 비동기 작업을 처리하는 데 유용한 도구 중 하나로 약속된 작업을 나타내는 객체를 만들 수 있게 한다. std::function과 함께 사용하여 비동기 계산을 캡슐화하고 그 결과를 나중에 검색하거나 다른 스레드에서 실행할 수 있게 해준다.

정리하자면, std::future 방식은 원하는 함수를 비동기적으로 실행하는 식이고, std::promise는 결과물을 promise를 통해 future로 받는 식이고, std::packaged_task는 원하는 함수의 실행 결과를 packaged_task를 통해 future로 받는 식이다.

```
#include "pch.h"
#include "CorePch.h"
#include <iostream>
#include <thread>
#include <atomic>
#include <mutex>
#include <future>

int64 Calculate() {
	int64 sum = 0;

	for (int32 i = 0; i < 100'000; i++) {
		sum += i;
	}

	return sum;
}

void PromiseWorker(std::promise<string>&& promise) {
	promise.set_value("Secret Message");
}

void TaskWorker(std::packaged_task<int64(void)>&& task) {
	task();
}

int main() {
	{
		std::future<int64> future = std::async(std::launch::async, Calculate);

		// 당장 결과물이 필요없다면 여기에 다른 작업을 진행

		// 일이 끝났는지 슬쩍 확인
		std::future_status status = future.wait_for(1ms);
		if (status == future_status::ready) {
		}

		int64 sum = future.get();
		// 결과물이 필요할 때 꺼냄

		// 멤버 함수도 호출 가능
		class Knight {
		public:
			int64 GetHp() { return 100; }
		};

		Knight knight;
		std::future<int64> future2 = std::async(std::launch::async, &Knight::GetHp, knight); // knight.GetHp();
	}

	// std::promise - future 객체를 만드는 두 번째 방법
	{
		// 미래에 결과물을 반환해줄거라 약속 - 계약서
		std::promise<string> promise;
		std::future<string> future = promise.get_future();
		
		thread t(PromiseWorker, std::move(promise));

		string message = future.get(); // 이제 future는 비었음
		cout << message << endl;

		t.join();
	}

	// std::packaged_task
	{
		std::packaged_task<int64(void)> task(Calculate);
		// int64(void)로 함수 타입과 맞춰줌
		std::future<int64> future = task.get_future();

		std::thread t(TaskWorker, std::move(task));

		int64 sum = future.get();
		cout << sum << endl;

		t.join();
	}
}
```

# 메모리 모델
atomic 연산에 한해서 모든 스레드가 동일 객체에 대해서 동일한 수정 순서를 관찰한다. 외부의 스레드에서 관찰하였을 때 유일하게 보증하는 것은 해당 변수가 0, 2, 1, 5와 같은 순서로 진행된다는 사실만이다. 중요한 것은 1은 스킵하고 0, 2, 5 순서로 관찰할 수도 있지만 2을 관찰하고 과거인 0을 관찰할 수는 없다는 점이다. 즉, 과거로는 갈 수 없지만 미래로는 갈 수 있다. 마치 우주에서 오는 항성의 빛을 관찰하는 것과 같다.

여기서 얘기하는 atomic 연산은 atomic 클래스를 사용한다는 것이 아니라 더 이상 쪼개질 수 없는 원자적 연산을 말한다. 그러니까 CPU가 한 번에 처리할 수 없는 연산이다. 따라서 CPU 성능에 영향을 받으므로 어떤 환경에서는 원자적인 연산이 어떤 환경에서는 원자적이지 않은 연산이 될 수도 있다.

```
{
    atomic<int64> v;
    cout << v.is_lock_free() << endl; // true이므로 원자적 연산
}

{
    struct Knight {
        int32 level;
        int32 hp;
        int32 mp;
    };

    atomic<Knight> v;
    cout << v.is_lock_free() << endl; // false이므로 원자적이지 않은 연산
}
```

해당 변수에 한해서는 해당 순서대로 관찰이 되겠지만 변수가 많다면 변수들끼리의 순서는 또 엎치락 뒤치락 뒤죽박죽이 된다. 그러니까 아토믹 연산을 한다고 해서 가시성 문제와 재배치 문제가 해결되지는 않는다.

메모리 모델은 여러 스레드 간의 메모리 공유와 관련된 규칙과 동작을 정의하는 것을 의미한다. 멀티스레드 환경에서는 여러 스레드가 동시에 실행되기 때문에 이들 간에 데이터를 공유하는 경우가 많다. 메모리 모델은 이러한 데이터 공유를 어떻게 관리하고, 어떻게 동기화되는지에 대한 규칙을 제공한다.

```
#include "pch.h"
#include "CorePch.h"
#include <iostream>
#include <thread>
#include <atomic>
#include <mutex>
#include <future>

atomic<bool> flag = false;

int main() {
	// flag = true;
	// flag.store(true);
	flag.store(true, memory_order::memory_order_seq_cst);
	// 일반적인 bool인지 아토믹인지 헷갈리므로 이렇게 사용

	// bool val = flag;
	// bool val = flag.load();
	bool val = flag.load(memory_order::memory_order_seq_cst);
	// 마찬가지로 일반 bool과 아토믹과의 구분을 위해 이렇게 사용

	// 이전 flag 값을 prev에 넣고 flag 값을 수정
	{
		// bool prev = flag;
		// flag = true;
		bool prev = flag.exchange(true);
		// 중간에 다른 스레드의 접근이 가능한 문제 방지
	}

	// CAS 조건부 수정
	{
		bool expected = false;
		bool desired = true;
		flag.compare_exchange_strong(expected, desired);
		// 예상값이 expected라면 desired로 변경

		flag.compare_exchange_weak(expected, desired);
		// strong과의 차이점은
		// 다른 스레드의 방해와 같은 상황으로 인한
		// Spurious Failure가 추가
		// strong은 그럼에도 불구하고 될때까지 하는 것
	}
}
```

```
#include "pch.h"
#include "CorePch.h"
#include <iostream>
#include <thread>
#include <atomic>
#include <mutex>
#include <future>

atomic<bool> ready;
int32 value;

void Producer() {
	value = 10;

	ready.store(true, memory_order::memory_order_release);
	// 절취선 1
	// 여기 위 코드들이 아래로 넘어올 수 없음
	// 위에서 재배치되는 것은 막지 않음
}

void Comsumer() {
	// 절취선 2
	// 아래 코드들이 위로 넘어갈 수 없음
	// 다른 스레드가 같은 변수를 acquire 한다면
	// 절취선 1 위의 내용들이 절취선 2 아래로 모두 갱신되어
	// 가시성 보장 
	while (ready.load(memory_order::memory_order_acquire) == false) {
	}

	cout << value << endl;
}

int main() {
	// 메모리 모델 (정책)
	// 1) Sequentially Consistent (seq_cst)
	// 2) Acquire-Release (acquire, release, acq_rel)
	// 3) Relaxed (relaxed)

	// 1. seq_cst : 가장 엄격 = 컴파일러 최적화 여지 적음 = 직관적
	// 기본값으로 가시성, 재배치 문제가 바로 해결됨
	
	// 2. acquire-release
	// 딱 중간에 해당
	// 한 쪽은 acquire, 다른 쪽은 release로 짝을 맞춤
	// release 명령 이전의 메모리 명령들이
	// 해당 명령 이후로 재배치 되는 것을 금지
	// 그리고 acquire로 같은 변수를 읽는 스레드가 있다면
	// release 이전의 명령들이 acquire 하는 순간에 관찰 가능
	
	// 3. relaxed  : 자유로움 = 컴파일러 최적화 여지 많음 = 직관적이지 못함
	// 가시성, 재배치 해결 안됨
	// 동일 객체애 대한 동일 관찰 순서만 보장

	// 기본적으로 그냥 seq_cst
	// 게다가 인텔이나 AMD의 경우 애당초 순차적 일관성을 보장
	// seq_cst를 써도 별다른 부하가 없음

	// atomic을 할 필요 없이 
	// std::atomic_thread_fence(memory_order::memory_order_release);로
	// 하나는 acquire, 또 다른 하나는 release로 하면
	// acquire-release와 동일하게 작용

	ready = false;
	value = 0;
	thread t1(Producer);
	thread t2(Comsumer);
	t1.join();
	t2.join();
}
```